<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<parent>
		<groupId>io.github.solven-eu.pepper</groupId>
		<artifactId>pepper-spark-parent</artifactId>
		<version>3.1</version>
	</parent>

	<artifactId>spark-docker</artifactId>
	<packaging>jar</packaging>

	<description>Helps building Docker image with various Spark|Hadoop configuration</description>

	<dependencies>
		<dependency>
			<!-- <groupId>com.databricks</groupId> -->
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-avro_${scala.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- Needed for Hive support, typically to access ABFSS -->
		<!-- We need hive to call .enableHiveSupport() -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.version}</artifactId>
		</dependency>

		<!-- For this projects, we always rely on Kubernetes -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-kubernetes_${scala.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- <dependency> -->
		<!-- We add hive-exec manually as we rejected the hive-exec@Spark to enabler 
			a more recent version -->
		<!-- We may need only hive-common -->
		<!-- <groupId>org.apache.hive</groupId> -->
		<!-- <artifactId>hive-exec</artifactId> -->
		<!-- </dependency> -->
		<dependency>
			<!-- We add hive-exec manually as we rejected the hive-exec@Spark to enabler 
				a more recent version -->
			<!-- We may need only hive-common -->
			<groupId>org.apache.hive</groupId>
			<artifactId>hive-common</artifactId>
		</dependency>

		<!-- We may need hadoop Azure in the core image as it will be necessary to 
			download the fatjar -->
		<!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-azure -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-azure</artifactId>
			<version>${hadoop.version}</version>
		</dependency>
	</dependencies>

	<build>
		<finalName>scala${scala.shortVersion}-spark${spark.shortVersion}-hadoop${hadoop.shortVersion}</finalName>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-assembly-plugin</artifactId>
				<configuration>
					<baseDirectory>jars</baseDirectory>
					<appendAssemblyId>false</appendAssemblyId>
					<attach>false</attach>
					<descriptors>
						<descriptor>assembly-spark.xml</descriptor>
					</descriptors>
				</configuration>
			</plugin>
		</plugins>
	</build>
</project>
