<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<parent>
		<groupId>com.github.cormoran-io.pepper</groupId>
		<artifactId>pepper-serialization</artifactId>
		<version>2.2-SNAPSHOT</version>
	</parent>

	<artifactId>spark-springboot</artifactId>
	<packaging>jar</packaging>

	<properties>
		<jacoco.instruction.ratio>0.0</jacoco.instruction.ratio>
		<jacoco.branch.ratio>0.0</jacoco.branch.ratio>

		<scala.version>2.11</scala.version>
		<!-- https://mvnrepository.com/artifact/org.scala-lang/scala-reflect -->
		<scala-lang.version>2.11.12</scala-lang.version>

		<!-- Most Spark distribution has this quite old Guava: as it easily leads -->
		<!-- to conflicts, we make sure we compile locally with this library -->
		<guava.version>14.0.1</guava.version>

		<hadoop.version>2.10.1</hadoop.version>
		<spark.version>2.4.8</spark.version>

		<janino.version>3.0.8</janino.version>
	</properties>

	<dependencyManagement>
		<dependencies>
			<dependency>
				<!-- https://stackoverflow.com/questions/42352091/spark-sql-fails-with-java-lang-noclassdeffounderror-org-codehaus-commons-compil -->
				<groupId>org.codehaus.janino</groupId>
				<artifactId>commons-compiler</artifactId>
				<version>${janino.version}</version>
			</dependency>
			<dependency>
				<!-- https://stackoverflow.com/questions/42352091/spark-sql-fails-with-java-lang-noclassdeffounderror-org-codehaus-commons-compil -->
				<groupId>org.codehaus.janino</groupId>
				<artifactId>janino</artifactId>
				<version>${janino.version}</version>
			</dependency>

			<dependency>
				<!-- https://mvnrepository.com/artifact/com.google.guava/guava -->
				<groupId>com.google.guava</groupId>
				<artifactId>guava</artifactId>
				<version>${guava.version}</version>
			</dependency>

			<dependency>
				<!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common -->
				<groupId>org.apache.hadoop</groupId>
				<artifactId>hadoop-common</artifactId>
				<version>${hadoop.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-core_${scala.version}</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-hive_${scala.version}</artifactId>
				<version>${spark.version}</version>
			</dependency>

			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scala-reflect</artifactId>
				<version>${scala-lang.version}</version>
			</dependency>
			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scala-library</artifactId>
				<version>${scala-lang.version}</version>
			</dependency>
			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scalap</artifactId>
				<version>${scala-lang.version}</version>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<dependencies>
		<dependency>
			<groupId>com.github.cormoran-io.pepper</groupId>
			<artifactId>pepper-spark_${scala.version}</artifactId>
			<version>${project.version}</version>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter</artifactId>
			<exclusions>
				<exclusion>
					<groupId>ch.qos.logback</groupId>
					<artifactId>logback-classic</artifactId>
				</exclusion>
			</exclusions>
		</dependency>


		<!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-azure -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-azure</artifactId>
			<!-- Oldest is 2.7.0 -->
			<!-- Youngest is 3.3.1 -->
			<version>${hadoop.version}</version>
			<optional>true</optional>
		</dependency>

		<dependency>
			<!-- https://cloudarchitected.com/2019/04/accessing-azure-data-lake-storage-gen2-from-clients/ -->
			<groupId>com.microsoft.azure</groupId>
			<artifactId>adal4j</artifactId>
			<version>1.6.3</version>
			<optional>true</optional>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-log4j2</artifactId>
		</dependency>
	</dependencies>

	<profiles>
		<!-- https://stackoverflow.com/questions/43883325/scala-spark-version-compatibility -->
		<profile>
			<id>scala-2.11</id>
			<properties>
				<scala.version>2.11</scala.version>
				<!-- https://mvnrepository.com/artifact/org.scala-lang/scala-reflect -->
				<scala-lang.version>2.11.12</scala-lang.version>
			</properties>
		</profile>
		<profile>
			<id>scala-2.12</id>
			<properties>
				<scala.version>2.12</scala.version>
				<!-- https://mvnrepository.com/artifact/org.scala-lang/scala-reflect -->
				<scala-lang.version>2.12.14</scala-lang.version>
			</properties>
		</profile>

		<!-- https://stackoverflow.com/questions/28458058/maven-shade-plugin-exclude-a-dependency-and-all-its-transitive-dependencies -->
		<!-- In these profile, we switch Spark dependencies as provided, so they 
			are not included in the shadedJar (without having to list transitive dependencies 
			individually) -->
		<profile>
			<id>spark-2.4</id>
			<properties>
				<spark.version>2.4.8</spark.version>
			</properties>
			<dependencies>
				<!-- In this profile, we switch Spark dependencies as provided, so they 
					are not included in the shadedJar (without having to list transitive dependencies 
					individually) -->
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-core_${scala.version}</artifactId>
					<version>${spark.version}</version>
					<scope>provided</scope>
				</dependency>
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-sql_${scala.version}</artifactId>
					<version>${spark.version}</version>
					<scope>provided</scope>
				</dependency>
			</dependencies>
		</profile>
		<profile>
			<!-- https://stackoverflow.com/questions/43883325/scala-spark-version-compatibility -->
			<id>spark-3.1</id>
			<properties>
				<!-- Spark3.1 requires Scala2.12+ -->
				<!-- Pick Scala version through -Pscala-2.1X -->
				<spark.version>3.1.2</spark.version>
			</properties>
			<dependencies>
				<!-- In this profile, we switch Spark dependencies as provided, so they 
					are not included in the shadedJar (without having to list transitive dependencies 
					individually) -->
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-core_${scala.version}</artifactId>
					<version>${spark.version}</version>
					<scope>provided</scope>
				</dependency>
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-sql_${scala.version}</artifactId>
					<version>${spark.version}</version>
					<scope>provided</scope>
				</dependency>
			</dependencies>
		</profile>

		<profile>
			<id>hadoop-2.7</id>
			<properties>
				<hadoop.version>2.7.7</hadoop.version>
			</properties>
		</profile>
		<profile>
			<id>hadoop-2.10</id>
			<properties>
				<hadoop.version>2.10.1</hadoop.version>
			</properties>
		</profile>
		<profile>
			<id>hadoop-3.2</id>
			<properties>
				<guava.version>27.0-jre</guava.version>
				<hadoop.version>3.2.2</hadoop.version>
			</properties>
		</profile>
		<profile>
			<id>hadoop-3.3</id>
			<properties>
				<guava.version>27.0-jre</guava.version>
				<hadoop.version>3.3.1</hadoop.version>
				<!-- <azure-hadoop.version>3.2.0</azure-hadoop.version> -->
			</properties>
		</profile>
	</profiles>

	<build>
		<plugins>
			<plugin>
				<!-- https://stackoverflow.com/questions/58014541/spring-spark-conflicts-between-jars-dependencies -->
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<dependencies>
					<dependency>
						<!-- We can not rely directly on spring-boot-maven-plugin -->
						<!-- as it has its own structure, which prevents loading it from another -->
						<!-- application ClassLoader, while it is exactly what's done by SparkSubmit -->
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-maven-plugin</artifactId>
						<version>2.5.4</version>
					</dependency>
				</dependencies>
				<configuration>
					<!-- <keepDependenciesWithProvidedScope>true</keepDependenciesWithProvidedScope> -->
					<createDependencyReducedPom>true</createDependencyReducedPom>

					<!-- We ensure the fatJar is a separate jar, so that this module can 
						be used as a standard dependency -->
					<shadedArtifactAttached>true</shadedArtifactAttached>
					<shadedClassifierName>exec</shadedClassifierName>

					<artifactSet>
						<excludes>
							<!-- By default, Spark has a local LOG4J12 jar: instead of mutating 
								the default Spark installation, we prefer show how to adjust our jar -->
							<exclude>ch.qos.logback:*</exclude>
						</excludes>
					</artifactSet>
					<filters>
						<filter>
							<artifact>*:*</artifact>
							<excludes>
								<!-- We remove signatures as, if they are valid for each dependency, 
									they are not valid for the assembly jar -->
								<exclude>META-INF/*.SF</exclude>
								<exclude>META-INF/*.DSA</exclude>
								<exclude>META-INF/*.RSA</exclude>
							</excludes>
						</filter>
					</filters>
				</configuration>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<transformers>
								<transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
									<resource>META-INF/spring.handlers</resource>
								</transformer>
								<transformer implementation="org.springframework.boot.maven.PropertiesMergingResourceTransformer">
									<resource>META-INF/spring.factories</resource>
								</transformer>
								<transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
									<resource>META-INF/spring.schemas</resource>
								</transformer>
								<transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" />
							</transformers>
						</configuration>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>
</project>